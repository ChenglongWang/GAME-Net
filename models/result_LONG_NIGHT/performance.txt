21-Sep-2022, 18:19:04
Device = NVIDIA GeForce MX450
Training time = 3.10 min
---------------------------------------------------------
GRAPH REPRESENTATION PARAMETERS
Voronoi tolerance = 0.5 Angstrom
Atomic radius scaling factor = 1.5
Second order metal neighbours inclusion = False
---------------------------------------------------------
GNN ARCHITECTURE
Activation function = ReLU
Convolutional layer = SAGE
Pooling layer = GMT
Number of convolutional layers = 3
Number of fully connected layers = 0
Depth of the layers = 256
Bias presence in the layers = False
---------------------------------------------------------
TRAINING PROCESS
Dataset Size = 2417
Data Split (Train/Val/Test) = 80-10-10 %
Target scaling = std
Target (train+val) mean = -72.597305 eV
Target (train+val) standard deviation = 19.425251 eV
Epochs = 200
Batch size = 16
Optimizer = Adam
Learning Rate scheduler = Reduce Loss On Plateau
Initial learning rate = 0.001
Minimum learning rate = 1e-08
Patience (lr-scheduler) = 5
Factor (lr-scheduler) = 0.7
Loss function = mae
---------------------------------------------------------
GNN PERFORMANCE
Test set size = 231
Mean Bias Error (MBE) = 0.010 eV
Mean Absolute Error (MAE) = 0.161 eV
Root Mean Square Error (RMSE) = 0.257 eV
Mean Absolute Percentage Error (MAPE) = 0.245 %
Error Standard Deviation = 0.257 eV
R2 = 1.000 
---------------------------------------------------------
OUTLIERS (TEST SET)
01) C4H6-Cd1          Error: -1.37 eV    (index=1)
02) C3H4-Au2          Error: -0.99 eV    (index=25)
03) C5H5N1-Pd8        Error: 1.10 eV    (index=33)
04) C9H7N1-Ru9        Error: 0.91 eV    (index=55)
05) C4H4S1-(g)        Error: 0.79 eV    (index=222)
