{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b2d4d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import get_graph_formula, scale_target, create_loaders\n",
    "from classes import *\n",
    "from constants import *\n",
    "from graph_tools import *\n",
    "from processed_datasets import *\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch_geometric  \n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f23b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune, init\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f447b5",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0722336",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_dataset = (#Intermediates_dataset,\n",
    "               RPCA_dataset,\n",
    "               #Benson_dataset,\n",
    "               group2_dataset,\n",
    "               group2b_dataset,\n",
    "               aromatics_dataset,\n",
    "               #Alloys_dataset,\n",
    "               aromatics2_dataset,\n",
    "               amides_dataset,\n",
    "               amidines_dataset,\n",
    "               oximes_dataset,\n",
    "               carbamate_esters_dataset,\n",
    "               group3S_dataset,\n",
    "               group3N_dataset,\n",
    "               group4_dataset,\n",
    "               gas_amides_dataset,\n",
    "               gas_amidines_dataset,\n",
    "               gas_aromatics_dataset,\n",
    "               gas_aromatics2_dataset,\n",
    "               gas_carbamate_esters_dataset,\n",
    "               gas_group2_dataset,\n",
    "               gas_group2b_dataset,\n",
    "               gas_group3N_dataset,\n",
    "               gas_group3S_dataset,\n",
    "               gas_group4_dataset,\n",
    "               gas_oximes_dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c02fab2",
   "metadata": {},
   "source": [
    "## Train/Test loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca1bacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(epoch, model, optimizer, train_loader, device):\n",
    "    \"\"\"\n",
    "    Helper function for training over an epoch. \n",
    "    For each batch in the epoch, the following actions are performed:\n",
    "    1) Move the batch to the selected device for training\n",
    "    2) Forward pass through the GNN model and loss function computation\n",
    "    3) Compute gradient of loss function wrt model parameters\n",
    "    4) Update model parameters\n",
    "    Args:\n",
    "        epoch(int): Epoch number.\n",
    "    Returns:\n",
    "        loss_all(float): Mean Squared Error (MSE) of the whole epoch.   \n",
    "    \"\"\"\n",
    "    model.train()  # Sets model in training mode\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()  # Sets the gradients of all tensors to zero\n",
    "        loss = F.mse_loss(model(data), data.y)\n",
    "        loss.backward()  # Compute the gradient of the loss function wrt parameters\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step() # Update the model parameters\n",
    "    loss_all /= len(train_loader.dataset)\n",
    "    return loss_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58e42c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(loader, model, std_tv, device):\n",
    "    \"\"\"\n",
    "    Helper function for validation/testing.\n",
    "    For each batch in the validation/test epoch, the following actions are performed:\n",
    "    1) Set the GNN model in evaluation mode\n",
    "    2) Move the batch to the selected device where the model is stored\n",
    "    3) Compute the Mean Absolute Error (MAE)\n",
    "    Args:\n",
    "        loader(Dataloader object): Dataset for validation/testing\n",
    "    Returns:\n",
    "        error(float): Mean Absolute Error (MAE)\n",
    "    \"\"\"\n",
    "    model.eval()  # Sets model in evaluation (inference) mode\n",
    "    error = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        error += (model(data) * std_tv - data.y * std_tv).abs().sum().item()  \n",
    "    error /= len(loader.dataset)\n",
    "    return error "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f405db08",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d65ee506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GNN(config, checkpoint_dir=None):\n",
    "    \"\"\"\n",
    "    Perform Training with hyperparameter tuning via RayTune.\n",
    "    Args:\n",
    "        config(dict): dictionary with search space\n",
    "    \"\"\"\n",
    "    train_loader, val_loader, test_loader = create_loaders(gnn_dataset, 5, batch_size=config[\"batch_size\"])\n",
    "    train_loader, val_loader, test_loader, mean_tv, std_tv = scale_target(train_loader, val_loader, test_loader)\n",
    "    device = \"cpu\"\n",
    "    model = Net(dim=config[\"dim\"], node_features=node_features).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=5, min_lr=1e-5)\n",
    "    best_val_error = None\n",
    "    for epoch in range(1, 301):\n",
    "        lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "        loss = train_loop(epoch, model, optimizer, train_loader, device)  \n",
    "        val_error = test_loop(val_loader, model, std_tv, device)\n",
    "        scheduler.step(val_error)  # Adjust the learning rate according to validation error\n",
    "\n",
    "        if best_val_error is None or val_error <= best_val_error:\n",
    "            #test_error = test_loop(test_loader)\n",
    "            best_val_error = val_error\n",
    "        test_error = test_loop(test_loader, model, std_tv, device)\n",
    "    \n",
    "    tune.report(MAE=test_error)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f533a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"dim\": tune.choice([32, 64, 128, 256, 512]),\n",
    "    \"batch_size\": tune.choice([16, 32, 64, 128])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2386dbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-15 16:57:56,518\tWARNING tune.py:580 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-15 16:57:57 (running for 00:00:01.25)<br>Memory usage on this node: 9.6/15.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/6 CPUs, 0/1 GPUs, 0.0/4.13 GiB heap, 0.0/2.07 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/santiago/ray_results/train_GNN_2022-03-15_16-57-56<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dim</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_GNN_ae0a5_00000</td><td>RUNNING </td><td>192.168.1.163:13530</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">  512</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m Training data = 2103 Validation data = 684 Test data = 684 (Total = 3471)\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m Target Scaling (Standardization) applied successfully\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m (Train+Val) mean: -64.38 eV\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m (Train+Val) standard deviation: 25.51 eV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-15 16:58:01 (running for 00:00:05.26)<br>Memory usage on this node: 9.9/15.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/6 CPUs, 0/1 GPUs, 0.0/4.13 GiB heap, 0.0/2.07 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/santiago/ray_results/train_GNN_2022-03-15_16-57-56<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dim</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_GNN_ae0a5_00000</td><td>RUNNING </td><td>192.168.1.163:13530</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">  512</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-15 16:58:06 (running for 00:00:10.28)<br>Memory usage on this node: 10.0/15.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/6 CPUs, 0/1 GPUs, 0.0/4.13 GiB heap, 0.0/2.07 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/santiago/ray_results/train_GNN_2022-03-15_16-57-56<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dim</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_GNN_ae0a5_00000</td><td>RUNNING </td><td>192.168.1.163:13530</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">  512</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-15 16:58:11 (running for 00:00:15.29)<br>Memory usage on this node: 10.0/15.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/6 CPUs, 0/1 GPUs, 0.0/4.13 GiB heap, 0.0/2.07 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/santiago/ray_results/train_GNN_2022-03-15_16-57-56<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dim</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_GNN_ae0a5_00000</td><td>RUNNING </td><td>192.168.1.163:13530</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">  512</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-15 16:58:16 (running for 00:00:20.30)<br>Memory usage on this node: 10.0/15.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/6 CPUs, 0/1 GPUs, 0.0/4.13 GiB heap, 0.0/2.07 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/santiago/ray_results/train_GNN_2022-03-15_16-57-56<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dim</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_GNN_ae0a5_00000</td><td>RUNNING </td><td>192.168.1.163:13530</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">  512</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-15 16:58:21 (running for 00:00:25.30)<br>Memory usage on this node: 10.0/15.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/6 CPUs, 0/1 GPUs, 0.0/4.13 GiB heap, 0.0/2.07 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/santiago/ray_results/train_GNN_2022-03-15_16-57-56<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dim</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_GNN_ae0a5_00000</td><td>RUNNING </td><td>192.168.1.163:13530</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">  512</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-15 16:58:26 (running for 00:00:30.31)<br>Memory usage on this node: 9.9/15.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/6 CPUs, 0/1 GPUs, 0.0/4.13 GiB heap, 0.0/2.07 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/santiago/ray_results/train_GNN_2022-03-15_16-57-56<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dim</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_GNN_ae0a5_00000</td><td>RUNNING </td><td>192.168.1.163:13530</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">  512</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-15 16:58:31 (running for 00:00:35.31)<br>Memory usage on this node: 9.9/15.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/6 CPUs, 0/1 GPUs, 0.0/4.13 GiB heap, 0.0/2.07 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/santiago/ray_results/train_GNN_2022-03-15_16-57-56<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dim</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_GNN_ae0a5_00000</td><td>RUNNING </td><td>192.168.1.163:13530</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">  512</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-15 16:58:36 (running for 00:00:40.32)<br>Memory usage on this node: 9.9/15.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/6 CPUs, 0/1 GPUs, 0.0/4.13 GiB heap, 0.0/2.07 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/santiago/ray_results/train_GNN_2022-03-15_16-57-56<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dim</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_GNN_ae0a5_00000</td><td>RUNNING </td><td>192.168.1.163:13530</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">  512</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-15 16:58:41 (running for 00:00:45.32)<br>Memory usage on this node: 9.9/15.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/6 CPUs, 0/1 GPUs, 0.0/4.13 GiB heap, 0.0/2.07 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/santiago/ray_results/train_GNN_2022-03-15_16-57-56<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dim</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_GNN_ae0a5_00000</td><td>RUNNING </td><td>192.168.1.163:13530</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">  512</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m 2022-03-15 16:58:43,916\tERROR function_runner.py:268 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m   File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m   File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/tune/function_runner.py\", line 330, in entrypoint\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m     return self._trainable_func(self.config, self._status_reporter,\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m   File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m   File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m   File \"/tmp/ipykernel_13413/289122469.py\", line 23, in train_GNN\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m NameError: name 'test_error' is not defined\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m   File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m   File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/tune/function_runner.py\", line 281, in run\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m   File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m   File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/tune/function_runner.py\", line 330, in entrypoint\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m     return self._trainable_func(self.config, self._status_reporter,\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m   File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m   File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m   File \"/tmp/ipykernel_13413/289122469.py\", line 23, in train_GNN\n",
      "\u001b[2m\u001b[36m(train_GNN pid=13530)\u001b[0m NameError: name 'test_error' is not defined\n",
      "2022-03-15 16:58:44,004\tERROR trial_runner.py:927 -- Trial train_GNN_ae0a5_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/tune/trial_runner.py\", line 893, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/tune/ray_trial_executor.py\", line 707, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/worker.py\", line 1733, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=13530, ip=192.168.1.163, repr=train_GNN)\n",
      "  File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/tune/trainable.py\", line 315, in train\n",
      "    result = self.step()\n",
      "  File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/tune/function_runner.py\", line 381, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/tune/function_runner.py\", line 531, in _report_thread_runner_error\n",
      "    raise TuneError(\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=13530, ip=192.168.1.163, repr=train_GNN)\n",
      "  File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "    self._entrypoint()\n",
      "  File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/tune/function_runner.py\", line 330, in entrypoint\n",
      "    return self._trainable_func(self.config, self._status_reporter,\n",
      "  File \"/home/santiago/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_13413/289122469.py\", line 23, in train_GNN\n",
      "NameError: name 'test_error' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_GNN_ae0a5_00000:\n",
      "  date: 2022-03-15_16-57-57\n",
      "  experiment_id: e7530ad7378b40ae98a9c3134582984b\n",
      "  hostname: santimor95-thinkpad-e14\n",
      "  node_ip: 192.168.1.163\n",
      "  pid: 13530\n",
      "  timestamp: 1647359877\n",
      "  trial_id: ae0a5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-15 16:58:44 (running for 00:00:47.49)<br>Memory usage on this node: 9.9/15.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/6 CPUs, 0/1 GPUs, 0.0/4.13 GiB heap, 0.0/2.07 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/santiago/ray_results/train_GNN_2022-03-15_16-57-56<br>Number of trials: 1/1 (1 ERROR)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dim</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_GNN_ae0a5_00000</td><td>ERROR   </td><td>192.168.1.163:13530</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">  512</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                          </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_GNN_ae0a5_00000</td><td style=\"text-align: right;\">           1</td><td>/home/santiago/ray_results/train_GNN_2022-03-15_16-57-56/train_GNN_ae0a5_00000_0_batch_size=16,dim=512_2022-03-15_16-57-56/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [train_GNN_ae0a5_00000])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13413/1711434454.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_GNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"min\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/GNN/lib/python3.9/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, queue_trials, loggers, _remote)\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [train_GNN_ae0a5_00000])"
     ]
    }
   ],
   "source": [
    "init(num_cpus=6)\n",
    "analysis = tune.run(train_GNN, config=search_space, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81955dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
