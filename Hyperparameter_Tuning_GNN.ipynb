{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2d4d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.loader import DataLoader\n",
    "from ray import tune, init, cluster_resources\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import ray\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "\n",
    "from nets import SantyxNet\n",
    "from functions import train_loop, test_loop, scale_target, create_loaders\n",
    "from processed_datasets import FG_dataset, BM_dataset\n",
    "\n",
    "BM_dataloader = DataLoader(BM_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ce254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERPARAMS = {}\n",
    "\n",
    "# NB: The values with tune.choice() are hyperparameters investigated, the others are fixed\n",
    "\n",
    "# Process-related\n",
    "HYPERPARAMS[\"test set\"] = True          \n",
    "HYPERPARAMS[\"splits\"] = 10              \n",
    "HYPERPARAMS[\"target scaling\"] = \"std\"   \n",
    "HYPERPARAMS[\"batch size\"] = tune.choice([16, 32, 64])           \n",
    "HYPERPARAMS[\"epochs\"] = 200               \n",
    "HYPERPARAMS[\"loss function\"] = torch.nn.functional.l1_loss   \n",
    "HYPERPARAMS[\"lr0\"] = tune.choice([0.01, 0.001, 0.0001])       \n",
    "HYPERPARAMS[\"patience\"] = tune.choice([5, 7, 10])              \n",
    "HYPERPARAMS[\"factor\"] = tune.choice([0.5, 0.7, 0.9])          \n",
    "HYPERPARAMS[\"minlr\"] = tune.choice([1e-7, 1e-8])             \n",
    "HYPERPARAMS[\"betas\"] = (0.9, 0.999)     \n",
    "HYPERPARAMS[\"eps\"] = tune.choice([1e-8, 1e-9])               \n",
    "HYPERPARAMS[\"weight decay\"] = 0         \n",
    "HYPERPARAMS[\"amsgrad\"] = tune.choice([True, False])          \n",
    "\n",
    "# Model-related\n",
    "HYPERPARAMS[\"dim\"] = tune.choice([64, 128, 256])                \n",
    "HYPERPARAMS[\"sigma\"] = torch.nn.ReLU()  \n",
    "HYPERPARAMS[\"bias\"] = tune.choice([True, False])              \n",
    "HYPERPARAMS[\"conv normalize\"] = False   \n",
    "HYPERPARAMS[\"conv root weight\"] = True\n",
    "HYPERPARAMS[\"pool ratio\"] = tune.choice([0.25, 0.5, 0.75])        \n",
    "HYPERPARAMS[\"pool heads\"] = tune.choice([2, 4, 6])\n",
    "HYPERPARAMS[\"pool seq\"] = tune.choice([[\"GMPool_I\"], \n",
    "                                       [\"GMPool_G\"], \n",
    "                                       [\"GMPool_G\", \"GMPool_I\"],\n",
    "                                       [\"GMPool_G\", \"SelfAtt\", \"GMPool_I\"],\n",
    "                                       [\"GMPool_G\", \"SelfAtt\", \"SelfAtt\", \"GMPool_I\"]])\n",
    "HYPERPARAMS[\"pool layer norm\"] = False "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f405db08",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ee506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(config, checkpoint_dir=None):\n",
    "    \"\"\"\n",
    "    Perform Training with hyperparameter tuning via RayTune.\n",
    "    Args:\n",
    "        config (dict): Dictionary with search space (hyperparameters)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate Datasets and scale target\n",
    "    train_loader, val_loader, test_loader = create_loaders(FG_dataset,\n",
    "                                                           config[\"splits\"],\n",
    "                                                           config[\"batch size\"], \n",
    "                                                           config[\"test set\"])\n",
    "    train_loader, val_loader, test_loader, mean, std = scale_target(train_loader,\n",
    "                                                                    val_loader,\n",
    "                                                                    test_loader, \n",
    "                                                                    mode=config[\"target scaling\"], \n",
    "                                                                    test=config[\"test set\"])\n",
    "    \n",
    "    # Select device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Call GNN model architecture\n",
    "    model = SantyxNet(dim=config[\"dim\"],\n",
    "                      sigma=config[\"sigma\"], \n",
    "                      bias=config[\"bias\"], \n",
    "                      conv_normalize=config[\"conv normalize\"], \n",
    "                      conv_root_weight=config[\"conv root weight\"], \n",
    "                      pool_ratio=config[\"pool ratio\"], \n",
    "                      pool_heads=config[\"pool heads\"], \n",
    "                      pool_seq=config[\"pool seq\"], \n",
    "                      pool_layer_norm=config[\"pool layer norm\"]).to(device)\n",
    "    \n",
    "    # Call optimizer and lr-scheduler\n",
    "    optimizer = Adam(model.parameters(),\n",
    "                     lr=config[\"lr0\"], \n",
    "                     betas=config[\"betas\"],\n",
    "                     eps=config[\"eps\"], \n",
    "                     weight_decay=config[\"weight decay\"], \n",
    "                     amsgrad=config[\"amsgrad\"])\n",
    "    lr_scheduler = ReduceLROnPlateau(optimizer,\n",
    "                                     mode='min',\n",
    "                                     factor=config[\"factor\"],\n",
    "                                     patience=config[\"patience\"],\n",
    "                                     min_lr=config[\"minlr\"])\n",
    "    \n",
    "    # Run training\n",
    "    for epoch in range(1, config[\"epochs\"]+1):\n",
    "        lr = lr_scheduler.optimizer.param_groups[0]['lr']\n",
    "        _, train_MAE = train_loop(model, device, train_loader, optimizer, config[\"loss function\"])  \n",
    "        val_MAE = test_loop(model, val_loader, device, std)\n",
    "        lr_scheduler.step(val_MAE)  # Adjust the learning rate according to validation error\n",
    "        if config[\"test set\"]:\n",
    "            test_MAE = test_loop(model, test_loader, device, std)                                           # Run epoch on test set\n",
    "            print('Epoch {:03d}: LR={:.7f}  Train MAE: {:.4f} eV  Validation MAE: {:.4f} eV '             \n",
    "                  'Test MAE: {:.4f} eV'.format(epoch, lr, train_MAE*std, val_MAE, test_MAE))\n",
    "        else:\n",
    "            print('Epoch {:03d}: LR={:.7f}  Train MAE: {:.6f} eV  Validation MAE: {:.6f} eV '\n",
    "                  .format(epoch, lr, train_MAE*std, val_MAE))  \n",
    "    \n",
    "    # Collect performance metric\n",
    "    BM_MAE = test_loop(model, BM_dataloader, device=device, std=std, mean=mean, scaled_graph_label=False)\n",
    "    FG_MAE = test_MAE             \n",
    "    tune.report(BM_MAE=BM_MAE, FG_MAE=FG_MAE)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f533a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5823560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(ignore_reinit_error=True)\n",
    "cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e86e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(metric=\"MAE\", \n",
    "                          mode=\"min\")\n",
    "\n",
    "algo = BayesOptSearch(random_search_steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2386dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(train_function,\n",
    "                    metric=\"MAE\",\n",
    "                    mode=\"min\",\n",
    "                    name=\"HypOpt2\",\n",
    "                    time_budget_s=3600*24,\n",
    "                    config=HYPERPARAMS,\n",
    "                    #scheduler=ASHAScheduler,\n",
    "                    #checkpoint_freq=5,\n",
    "                    #progress_reporter=CLIReporter,\n",
    "                    resources_per_trial={\"cpu\":8, \"gpu\":1},\n",
    "                    num_samples=5, \n",
    "                    verbose=1,\n",
    "                    log_to_file=True, \n",
    "                    local_dir=\"./Hyperparameter_Optimization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81955dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a31cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.best_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72cb329",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.default_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094bc123",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d10248a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('GNN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "929eb757b548c43686da14be07befd842a942a01eb9dc843387956885175000a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
