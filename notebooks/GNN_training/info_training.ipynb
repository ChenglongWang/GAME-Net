{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = \"/home/smorandi/teklahome/best_model_paper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = pd.read_csv(os.path.join(training_path, \"train_set.csv\"), sep=\"\\t\")\n",
    "val_samples = pd.read_csv(os.path.join(training_path, \"validation_set.csv\"), sep=\"\\t\")\n",
    "test_samples = pd.read_csv(os.path.join(training_path, \"test_set.csv\"), sep=\"\\t\")\n",
    "\n",
    "print(\"Train samples: \", train_samples.shape)\n",
    "print(\"Val samples: \", val_samples.shape)\n",
    "print(\"Test samples: \", test_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the stdout.txt file and extract the LR, Train MAE, Val MAE, Test MAE\n",
    "txt_file = os.path.join(training_path, \"stdout.txt\")\n",
    "lr, train_mae, val_mae, test_mae = [], [], [], []\n",
    "with open(txt_file, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[6:206]:\n",
    "        lr.append(float(line.split(\" \")[2][3:]))\n",
    "        train_mae.append(float(line.split(\" \")[6]))\n",
    "        val_mae.append(float(line.split(\" \")[11]))\n",
    "        test_mae.append(float(line.split(\" \")[15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_samples[\"True [eV]\"].values\n",
    "val_labels = val_samples[\"True [eV]\"].values\n",
    "test_labels = test_samples[\"True [eV]\"].values\n",
    "epoch = np.arange(1, 201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do plot of the distribution of the labels\n",
    "train_col = \"#5fbcd3ff\"\n",
    "val_col = \"#de8787ff\"\n",
    "test_col = \"#ffd42aff\"\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(15/2.54, 21/2.54))\n",
    "ax[0] = sns.kdeplot(train_labels, label=\"Train\", ax=ax[0], color=train_col, linewidth=2)\n",
    "ax[0] = sns.kdeplot(val_labels, label=\"Validation\", ax=ax[0], color=val_col, linewidth=2)\n",
    "ax[0] = sns.kdeplot(test_labels, label=\"Test\", ax=ax[0], color=test_col, linewidth=2)\n",
    "params = {'mathtext.default': 'regular'}          \n",
    "plt.rcParams.update(params)\n",
    "plt.rcParams.update({'font.family': 'Arial'})\n",
    "ax[0].set_xlabel('$\\mathit{E}_{tot}^{DFT} - \\mathit{E}_{slab}^{DFT}$ / eV')\n",
    "ax[0].set_ylabel('Density / -')\n",
    "ax[0].set_title('Target distribution')\n",
    "# show legend\n",
    "ax[0].legend()\n",
    "#ax[0].grid()\n",
    "# y-ticks labels in scientific notation\n",
    "ax[0].ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,0))\n",
    "\n",
    "\n",
    "#subplot for MAE trend of train val test sets as function of epochs\n",
    "ax[1].plot(epoch, train_mae, label=\"Train\", color=train_col, linewidth=2)\n",
    "ax[1].plot(epoch, val_mae, label=\"Validation\", color=val_col, linewidth=2)\n",
    "ax[1].plot(epoch, test_mae, label=\"Test\", color=test_col, linewidth=2)\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('MAE / eV')\n",
    "ax[1].set_title('Training process')\n",
    "ax[1].set_ylim(0.0, 2.0)\n",
    "ax[1].set_xlim(0, 200)\n",
    "ax[1].set_xticks(np.arange(0, 201, 50))\n",
    "ax[1].set_yticks(np.arange(0, 2.1, 0.5))\n",
    "ax[1].legend()\n",
    "# Generate a smaller canvas inside ax[1] to do zoom in the last epochs\n",
    "axins = ax[1].inset_axes([0.6, 0.25, 0.3, 0.3])\n",
    "axins.plot(epoch, train_mae, label=\"Train\", color=train_col)\n",
    "axins.plot(epoch, val_mae, label=\"Validation\", color=val_col)\n",
    "axins.plot(epoch, test_mae, label=\"Test\", color=test_col)\n",
    "axins.set_xlim(190, 200)\n",
    "axins.set_ylim(0.1, 0.2)\n",
    "axins.set_xticks(np.arange(190, 201, 5))\n",
    "# Connect smaller canvas to the x-axis (last 10 epochs of the main plot)\n",
    "axins.xaxis.set_visible(False)\n",
    "ax[1].indicate_inset_zoom(axins)\n",
    "\n",
    "\n",
    "#subplot for learning rate trend in logarithmic scale\n",
    "ax[2].plot(epoch, np.log10(lr), label=\"Learning rate\", linewidth=2)\n",
    "ax[2].set_xlabel('Epoch')\n",
    "ax[2].set_ylabel('$log_{10}(lr)$ / -')\n",
    "ax[2].set_title('Learning rate')\n",
    "ax[2].set_ylim(-6.0, -2.5)\n",
    "ax[2].set_xlim(0, 200)\n",
    "ax[2].set_xticks(np.arange(0, 201, 50))\n",
    "ax[2].set_yticks(np.arange(-6, -2.5, 1.0))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"training_example.png\", dpi=500, transparent=True)\n",
    "plt.savefig(\"training_example.svg\", dpi=500, transparent=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
