{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "controversial-lodge",
   "metadata": {},
   "source": [
    "# FG_Dataset lmdb creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916b9464-89c0-493a-a0cc-c933a81a83f8",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2f4f25d8-b18f-4ae3-a4bc-4c4110ad6c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT_DIR = Path(\"./datasets/\")              # Working directory\n",
    "\n",
    "TARBALL = ROOT_DIR/\"FG_dataset_lite.tar.xz\" # Location of the dataset tarball\n",
    "# TARBALL = None                            # Set to False or None to avoid extraction.\n",
    "DS_DIR = ROOT_DIR/\"FG_dataset_lite\"         # Dir of the initial Dataset\n",
    "DS_DIR_OUT = Path(\"./lmdb/lmdb_crossval\")   # Dir of the output dataset\n",
    "INITIAL_GEOMETRY = \"contcar\"                # Either look for contcar or poscar files\n",
    "SPLIT_CV = { \"seed\": 42                     # Seed that will be used during the random splitting\n",
    "            ,\"n_splits\": 5                  # Number of splits\n",
    "            ,\"val_size\": 1                  # Number of splits in the validation set\n",
    "            ,\"test_size\": 1 }               # Number of splits in the test set\n",
    "#SPLIT_CV = False                           # Set it to False or None to avoid splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd11b289-e6f5-4b07-aaa6-c95818c41eca",
   "metadata": {},
   "source": [
    "## Extract Tarball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3bac17fd-fe47-4599-9beb-1584d93db158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tarball to DS_DIR location\n",
    "if TARBALL:\n",
    "    import tarfile\n",
    "    tar_ds = tarfile.open(TARBALL, mode=\"r:xz\")\n",
    "    tar_ds.extractall(DS_DIR)\n",
    "    tar_ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cab2dc0-6d36-449b-8e29-3c97fc9a2add",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5f4d8d3b-88bd-4fdd-a8ca-576ab9a649c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read a file with two columns and transform it to a dictionary\n",
    "def read_two_columns(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        return map(\n",
    "            lambda l: l.split()\n",
    "            , f.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01710d4c-0e79-4747-bedf-e3205bf907c6",
   "metadata": {},
   "source": [
    "## Read structures and Energies\n",
    "\n",
    "Read structures, inital and final energies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f9904ceb-3ae2-4da9-91d5-4314169c3241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from ase.io.vasp import read_vasp, read_vasp_out\n",
    "from ase.calculators.singlepoint import SinglePointCalculator\n",
    "\n",
    "# Get energies in files\n",
    "iener_dict = dict(read_two_columns(DS_DIR/\"energies_i.dat\"))\n",
    "fener_dict = dict(read_two_columns(DS_DIR/\"energies.dat\"))\n",
    "\n",
    "def get_struct(fname):\n",
    "    final = read_vasp(fname)\n",
    "    final._calc = SinglePointCalculator(final, energy=float(fener_dict[fname.stem]))\n",
    "    return final                                \n",
    "                                                \n",
    "strct_dict = dict(map(\n",
    "    lambda d: (d.stem, get_struct(d))\n",
    "    , DS_DIR.glob(f\"./*/*/*.{INITIAL_GEOMETRY}\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4cbf39-9cc7-4fb5-af83-2c66bd51fd57",
   "metadata": {},
   "source": [
    "## Get Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6035cb0e-42cb-4a55-a6f6-1a8cd1364d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from itertools import chain\n",
    "\n",
    "def reduce_grp(d, i):\n",
    "    match i:\n",
    "        case (k, v) if k in d: d[k].append(v)\n",
    "        case (k, v): d[k] = [v]\n",
    "    return d\n",
    "\n",
    "groups_direct = dict(read_two_columns(DS_DIR/\"groups.dat\"))\n",
    "groups_invert = map(\n",
    "    lambda xs: xs[::-1]\n",
    "    , groups_direct.items())\n",
    "\n",
    "groups_dict = reduce(\n",
    "    reduce_grp\n",
    "    , groups_invert\n",
    "    , {})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a30826e-5113-440a-a01a-85b5e7cef539",
   "metadata": {},
   "source": [
    "## Samples Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "29285046-6e70-423b-9826-d7eb295f16e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a filter to avoid collecting the metals\n",
    "filter_fn = lambda x: \"0000\" not in x\n",
    "# Use only final energies if contcar is selected\n",
    "if INITIAL_GEOMETRY == \"contcar\": \n",
    "    ener_pvt_dict = fener_dict\n",
    "else:\n",
    "    ener_pvt_dict = iener_dict\n",
    "\n",
    "ener_strct_dict = dict(map(\n",
    "    lambda x: (x, dict(name=x\n",
    "                       , fener=float(fener_dict[x])\n",
    "                       , iener=float(ener_pvt_dict[x])\n",
    "                       , image=strct_dict[x]\n",
    "                       , group=groups_direct[x]))\n",
    "    , filter(filter_fn, fener_dict.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed1346f-198c-474f-9dd8-aaae6a1863ad",
   "metadata": {},
   "source": [
    "## Extract Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ae3527cc-7572-4038-b335-2a25991dac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocpmodels.preprocessing import AtomsToGraphs\n",
    "import torch\n",
    "\n",
    "a2g = AtomsToGraphs(\n",
    "    max_neigh=50,\n",
    "    radius=6,\n",
    "    r_energy=True,\n",
    "    r_forces=False,\n",
    "    r_distances=False,\n",
    "    r_fixed=True,\n",
    ")\n",
    "\n",
    "def read_entry_extract_features(a2g, strc):\n",
    "    tags = strc.get_tags()\n",
    "    data_objects = a2g.convert_all([strc], disable_tqdm=True)\n",
    "    data_objects[0].tags = torch.LongTensor(tags)\n",
    "    return data_objects\n",
    "\n",
    "def model_dict(xs):\n",
    "    idx = 0\n",
    "    out_dict = {}\n",
    "    for key, value in xs.items():\n",
    "        data_objects = read_entry_extract_features(a2g, value['image'])\n",
    "        init = data_objects[0]\n",
    "    \n",
    "        init.y_init = value[\"iener\"]\n",
    "        init.y_relaxed = init.y\n",
    "        del init.y\n",
    "        # As we are performing a IS2RE the final structure is not needed.\n",
    "        init.pos_relaxed = init.pos \n",
    "    \n",
    "        init.sid = idx\n",
    "        # Saving name and group for later identification.\n",
    "        init.name = value[\"name\"]\n",
    "        init.group = value[\"group\"]\n",
    "        \n",
    "        if init.edge_index.shape[1] == 0:\n",
    "            print(\"no neighbors\", idx)\n",
    "            continue\n",
    "        idx += 1\n",
    "        out_dict[key] = init\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f26c5751-22a6-4dc6-8d0a-7eb81ef2ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ase_dict = model_dict(ener_strct_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b76dc4ef-6a8c-4136-8adc-371ca49df395",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in the dataset: 3255\n"
     ]
    }
   ],
   "source": [
    "print(f\"Samples in the dataset: {len(ase_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cb6807-2763-41c1-8960-70c349d6b2d4",
   "metadata": {},
   "source": [
    "## Process Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556d323a-d03c-4783-aae8-a3d5322d9432",
   "metadata": {},
   "source": [
    "## Split Sets\n",
    "\n",
    "split_ds function splits the dataset into n_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2798e3b0-b107-455a-92c1-243358e4fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_ds(ase_dict, groups_dict, seed=42, n_splits=5, val_size=1, test_size=1):\n",
    "    from random import seed, shuffle\n",
    "    from collections import deque\n",
    "    from numpy import array_split\n",
    "    from itertools import chain, combinations, product\n",
    "    \n",
    "    seed(seed)\n",
    "\n",
    "    # Randomly shuffle the values stored in groups dict\n",
    "    deque(map(\n",
    "        shuffle\n",
    "        , groups_dict.values())\n",
    "        , maxlen=0)\n",
    "\n",
    "    # Filter structures that are in groups_dict but are not present\n",
    "    # in ase_dict\n",
    "    filtered_groups_dict = dict(map(\n",
    "        lambda xs: (xs[0]\n",
    "                    , tuple(filter(lambda x: x in ase_dict.keys()\n",
    "                             , xs[1])))\n",
    "        , groups_dict.items()))\n",
    "    \n",
    "    # Split the groups entries equally into n_splits slices\n",
    "    slices = reduce(\n",
    "        lambda l, t: map(lambda x: tuple(chain.from_iterable(x))\n",
    "                         , zip(l, t))\n",
    "        , map(lambda x: array_split(x, n_splits)\n",
    "            , filtered_groups_dict.values())\n",
    "        , [[]]*n_splits)\n",
    "\n",
    "    k_sets = set(map(\n",
    "        lambda x: tuple(map(ase_dict.get, x))\n",
    "        , slices))\n",
    "    \n",
    "    val_set = combinations(k_sets, val_size)\n",
    "    test_set = combinations(k_sets, test_size)\n",
    "    # Quick filter to discard combinations that lead to intersections between\n",
    "    # validation and test datasets.\n",
    "    val_test_comb = filter(\n",
    "        lambda xs: not set(xs[0]).intersection(set(xs[1]))\n",
    "        , product(val_set, test_set))\n",
    "    \n",
    "    # Chain the slices into training test and val\n",
    "    chain_n_tuple = lambda xs: tuple(chain.from_iterable(xs))\n",
    "    return map(\n",
    "        lambda xs: (chain_n_tuple(k_sets.difference(set(set(chain.from_iterable(xs)))))\n",
    "                    , chain_n_tuple(xs[0])\n",
    "                    , chain_n_tuple(xs[1]))\n",
    "        , val_test_comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-haiti",
   "metadata": {},
   "source": [
    "## Write data to LMDB\n",
    "\n",
    "Write the three datasets into the lmdb format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "073737ac-cbd4-49c0-a093-e50dc286b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "def dump_db(xs, db_path):\n",
    "    db = lmdb.open(\n",
    "        str(db_path),\n",
    "        map_size=1099511627776 * 2,\n",
    "        subdir=False,\n",
    "        meminit=False,\n",
    "        map_async=True,\n",
    "    )\n",
    "    idx = 0\n",
    "    for value in xs:\n",
    "        txn = db.begin(write=True)\n",
    "        txn.put(f\"{idx}\".encode(\"ascii\"), pickle.dumps(value, protocol=-1))\n",
    "        txn.commit()\n",
    "        db.sync()\n",
    "        idx += 1\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ab3c0d8-1789-4773-b638-8704111ca8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from os import makedirs\n",
    "\n",
    "mkdir_p = lambda p: p.is_dir() or makedirs(p)\n",
    "\n",
    "# Write three different lmdb for each of the splittings.\n",
    "if SPLIT_CV:\n",
    "    splitted_sets = split_ds(ase_dict, groups_dict, **SPLIT_CV)\n",
    "    for idx, n_set in enumerate(splitted_sets):\n",
    "        train, test, val = n_set\n",
    "        dpath = DS_DIR_OUT/str(idx)\n",
    "        mkdir_p(dpath)\n",
    "        dump_db(train, dpath/\"train.lmdb\")\n",
    "        dump_db(test, dpath/\"test.lmdb\")\n",
    "        dump_db(val, dpath/\"val.lmdb\")\n",
    "else:\n",
    "    dpath = DS_DIR_OUT\n",
    "    mkdir_p(dpath)\n",
    "    dump_db(ase_dict, dpath/\"test.lmdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac0791-0526-4dd2-b48b-7f61926d339f",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e40b3e-b60b-43de-8fab-783054e566a7",
   "metadata": {},
   "source": [
    "### Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "660af0bf-d303-4c23-a3cd-bf969f460ffc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nix/store/kxq814fy033bhg7hnqafxasw1il3fp99-python3.10-pandas-1.4.4/lib/python3.10/site-packages/pandas/core/frame.py:710: UserWarning: SinglePointLmdbDataset is deprecated and will be removed in the future.Please use 'LmdbDataset' instead.\n",
      "  data = list(data)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ocpmodels.datasets import SinglePointLmdbDataset\n",
    "from pathlib import Path\n",
    "\n",
    "if SPLIT_CV:\n",
    "    target_glob = \"./*/*.lmdb\"\n",
    "else:\n",
    "    target_glob = \"./*.lmdb\"\n",
    "\n",
    "# Extract some useful metrics from the datasets\n",
    "# This step is not needed and can be done before without\n",
    "# needing to read the datasets again, but I used it as a\n",
    "# sanity check, as it is easy to detect errors.\n",
    "def get_metrics(lmdb_ds_path):\n",
    "    ds_arr = np.asarray(tuple(\n",
    "        map(\n",
    "            lambda x: x.y_relaxed\n",
    "            , SinglePointLmdbDataset({\"src\": str(lmdb_ds_path)})))\n",
    "        , dtype=float)\n",
    "    return {\n",
    "        \"mean\": np.mean(ds_arr)\n",
    "        , \"std\": np.std(ds_arr)\n",
    "        , \"idx\": lmdb_ds_path.parent.name\n",
    "        , \"split\": lmdb_ds_path.stem\n",
    "        , \"path\": lmdb_ds_path\n",
    "        , \"samples\": ds_arr.shape[0]\n",
    "    }\n",
    "\n",
    "metrics_df = pd.DataFrame(map(\n",
    "    get_metrics\n",
    "    , DS_DIR_OUT.glob((\"./*.lmdb\", \"./*/*.lmdb\")[bool(SPLIT_CV)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "674ce07d-777e-48cd-accd-1dbe283775c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written metrics for the ds in data/toy_ds\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "deque(map(lambda xs: xs[1].to_csv( Path(xs[1][\"path\"].iloc[0]).parent/\"metrics.csv\"\n",
    "                            , header=False\n",
    "                            , index=False)\n",
    "    , metrics_df.groupby(\"idx\")[[\"split\", \"path\", \"mean\", \"std\"]]))\n",
    "\n",
    "print(f\"Written metrics for the ds in {DS_DIR_OUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6573e9-458a-4aeb-b60d-c9d50eee169d",
   "metadata": {},
   "source": [
    "### Show Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1e838ca6-f30b-442c-ab89-ae2de523eef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>idx</th>\n",
       "      <th>split</th>\n",
       "      <th>path</th>\n",
       "      <th>samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-321.685422</td>\n",
       "      <td>150.912688</td>\n",
       "      <td>4</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/4/val.lmdb</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-332.431521</td>\n",
       "      <td>146.242296</td>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/4/test.lmdb</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-318.989351</td>\n",
       "      <td>152.354499</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/4/train.lmdb</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-321.417012</td>\n",
       "      <td>153.527547</td>\n",
       "      <td>14</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/14/test.lmdb</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-321.964564</td>\n",
       "      <td>149.681418</td>\n",
       "      <td>14</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/14/train.lmdb</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-323.746765</td>\n",
       "      <td>152.143822</td>\n",
       "      <td>14</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/14/val.lmdb</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-321.417012</td>\n",
       "      <td>153.527547</td>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/13/test.lmdb</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-319.077396</td>\n",
       "      <td>151.483806</td>\n",
       "      <td>13</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/13/train.lmdb</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-332.431521</td>\n",
       "      <td>146.242296</td>\n",
       "      <td>13</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/13/val.lmdb</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-311.808000</td>\n",
       "      <td>151.121444</td>\n",
       "      <td>19</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/19/test.lmdb</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-325.952307</td>\n",
       "      <td>149.862578</td>\n",
       "      <td>19</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/19/train.lmdb</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-321.417012</td>\n",
       "      <td>153.527547</td>\n",
       "      <td>19</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/19/val.lmdb</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-325.860653</td>\n",
       "      <td>150.748462</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/3/train.lmdb</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-321.685422</td>\n",
       "      <td>150.912688</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/3/test.lmdb</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-311.808000</td>\n",
       "      <td>151.121444</td>\n",
       "      <td>3</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/3/val.lmdb</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-332.431521</td>\n",
       "      <td>146.242296</td>\n",
       "      <td>9</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/9/val.lmdb</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-318.298420</td>\n",
       "      <td>151.928168</td>\n",
       "      <td>9</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/9/train.lmdb</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-323.746765</td>\n",
       "      <td>152.143822</td>\n",
       "      <td>9</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/9/test.lmdb</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-311.808000</td>\n",
       "      <td>151.121444</td>\n",
       "      <td>7</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/7/val.lmdb</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-332.431521</td>\n",
       "      <td>146.242296</td>\n",
       "      <td>7</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/7/test.lmdb</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-322.284122</td>\n",
       "      <td>152.202623</td>\n",
       "      <td>7</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/7/train.lmdb</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-311.808000</td>\n",
       "      <td>151.121444</td>\n",
       "      <td>17</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/17/test.lmdb</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-332.431521</td>\n",
       "      <td>146.242296</td>\n",
       "      <td>17</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/17/val.lmdb</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-322.284122</td>\n",
       "      <td>152.202623</td>\n",
       "      <td>17</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/17/train.lmdb</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-321.964564</td>\n",
       "      <td>149.681418</td>\n",
       "      <td>10</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/10/train.lmdb</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-323.746765</td>\n",
       "      <td>152.143822</td>\n",
       "      <td>10</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/10/test.lmdb</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-321.417012</td>\n",
       "      <td>153.527547</td>\n",
       "      <td>10</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/10/val.lmdb</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-321.685422</td>\n",
       "      <td>150.912688</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/0/test.lmdb</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-318.989351</td>\n",
       "      <td>152.354499</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/0/train.lmdb</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-332.431521</td>\n",
       "      <td>146.242296</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/0/val.lmdb</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-325.176057</td>\n",
       "      <td>150.346956</td>\n",
       "      <td>18</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/18/train.lmdb</td>\n",
       "      <td>1951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-323.746765</td>\n",
       "      <td>152.143822</td>\n",
       "      <td>18</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/18/val.lmdb</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-311.808000</td>\n",
       "      <td>151.121444</td>\n",
       "      <td>18</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/18/test.lmdb</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-321.685422</td>\n",
       "      <td>150.912688</td>\n",
       "      <td>12</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/12/val.lmdb</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-322.652096</td>\n",
       "      <td>150.099840</td>\n",
       "      <td>12</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/12/train.lmdb</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-321.417012</td>\n",
       "      <td>153.527547</td>\n",
       "      <td>12</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/12/test.lmdb</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-321.874951</td>\n",
       "      <td>150.566060</td>\n",
       "      <td>8</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/8/train.lmdb</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-323.746765</td>\n",
       "      <td>152.143822</td>\n",
       "      <td>8</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/8/test.lmdb</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-321.685422</td>\n",
       "      <td>150.912688</td>\n",
       "      <td>8</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/8/val.lmdb</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-321.417012</td>\n",
       "      <td>153.527547</td>\n",
       "      <td>2</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/2/val.lmdb</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-321.685422</td>\n",
       "      <td>150.912688</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/2/test.lmdb</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-322.652096</td>\n",
       "      <td>150.099840</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/2/train.lmdb</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-318.298420</td>\n",
       "      <td>151.928168</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/5/train.lmdb</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-332.431521</td>\n",
       "      <td>146.242296</td>\n",
       "      <td>5</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/5/test.lmdb</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-323.746765</td>\n",
       "      <td>152.143822</td>\n",
       "      <td>5</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/5/val.lmdb</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-321.417012</td>\n",
       "      <td>153.527547</td>\n",
       "      <td>15</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/15/test.lmdb</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-325.952307</td>\n",
       "      <td>149.862578</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/15/train.lmdb</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-311.808000</td>\n",
       "      <td>151.121444</td>\n",
       "      <td>15</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/15/val.lmdb</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-323.746765</td>\n",
       "      <td>152.143822</td>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/11/test.lmdb</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-311.808000</td>\n",
       "      <td>151.121444</td>\n",
       "      <td>11</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/11/val.lmdb</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-325.176057</td>\n",
       "      <td>150.346956</td>\n",
       "      <td>11</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/11/train.lmdb</td>\n",
       "      <td>1951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-321.874951</td>\n",
       "      <td>150.566060</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/1/train.lmdb</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>-323.746765</td>\n",
       "      <td>152.143822</td>\n",
       "      <td>1</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/1/val.lmdb</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-321.685422</td>\n",
       "      <td>150.912688</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/1/test.lmdb</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>-332.431521</td>\n",
       "      <td>146.242296</td>\n",
       "      <td>6</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/6/test.lmdb</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-321.417012</td>\n",
       "      <td>153.527547</td>\n",
       "      <td>6</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/6/val.lmdb</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-319.077396</td>\n",
       "      <td>151.483806</td>\n",
       "      <td>6</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/6/train.lmdb</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>-321.685422</td>\n",
       "      <td>150.912688</td>\n",
       "      <td>16</td>\n",
       "      <td>val</td>\n",
       "      <td>data/toy_ds/16/val.lmdb</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-325.860653</td>\n",
       "      <td>150.748462</td>\n",
       "      <td>16</td>\n",
       "      <td>train</td>\n",
       "      <td>data/toy_ds/16/train.lmdb</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-311.808000</td>\n",
       "      <td>151.121444</td>\n",
       "      <td>16</td>\n",
       "      <td>test</td>\n",
       "      <td>data/toy_ds/16/test.lmdb</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean         std idx  split                       path  samples\n",
       "0  -321.685422  150.912688   4    val     data/toy_ds/4/val.lmdb      650\n",
       "1  -332.431521  146.242296   4   test    data/toy_ds/4/test.lmdb      650\n",
       "2  -318.989351  152.354499   4  train   data/toy_ds/4/train.lmdb     1955\n",
       "3  -321.417012  153.527547  14   test   data/toy_ds/14/test.lmdb      651\n",
       "4  -321.964564  149.681418  14  train  data/toy_ds/14/train.lmdb     1952\n",
       "5  -323.746765  152.143822  14    val    data/toy_ds/14/val.lmdb      652\n",
       "6  -321.417012  153.527547  13   test   data/toy_ds/13/test.lmdb      651\n",
       "7  -319.077396  151.483806  13  train  data/toy_ds/13/train.lmdb     1954\n",
       "8  -332.431521  146.242296  13    val    data/toy_ds/13/val.lmdb      650\n",
       "9  -311.808000  151.121444  19   test   data/toy_ds/19/test.lmdb      652\n",
       "10 -325.952307  149.862578  19  train  data/toy_ds/19/train.lmdb     1952\n",
       "11 -321.417012  153.527547  19    val    data/toy_ds/19/val.lmdb      651\n",
       "12 -325.860653  150.748462   3  train   data/toy_ds/3/train.lmdb     1953\n",
       "13 -321.685422  150.912688   3   test    data/toy_ds/3/test.lmdb      650\n",
       "14 -311.808000  151.121444   3    val     data/toy_ds/3/val.lmdb      652\n",
       "15 -332.431521  146.242296   9    val     data/toy_ds/9/val.lmdb      650\n",
       "16 -318.298420  151.928168   9  train   data/toy_ds/9/train.lmdb     1953\n",
       "17 -323.746765  152.143822   9   test    data/toy_ds/9/test.lmdb      652\n",
       "18 -311.808000  151.121444   7    val     data/toy_ds/7/val.lmdb      652\n",
       "19 -332.431521  146.242296   7   test    data/toy_ds/7/test.lmdb      650\n",
       "20 -322.284122  152.202623   7  train   data/toy_ds/7/train.lmdb     1953\n",
       "21 -311.808000  151.121444  17   test   data/toy_ds/17/test.lmdb      652\n",
       "22 -332.431521  146.242296  17    val    data/toy_ds/17/val.lmdb      650\n",
       "23 -322.284122  152.202623  17  train  data/toy_ds/17/train.lmdb     1953\n",
       "24 -321.964564  149.681418  10  train  data/toy_ds/10/train.lmdb     1952\n",
       "25 -323.746765  152.143822  10   test   data/toy_ds/10/test.lmdb      652\n",
       "26 -321.417012  153.527547  10    val    data/toy_ds/10/val.lmdb      651\n",
       "27 -321.685422  150.912688   0   test    data/toy_ds/0/test.lmdb      650\n",
       "28 -318.989351  152.354499   0  train   data/toy_ds/0/train.lmdb     1955\n",
       "29 -332.431521  146.242296   0    val     data/toy_ds/0/val.lmdb      650\n",
       "30 -325.176057  150.346956  18  train  data/toy_ds/18/train.lmdb     1951\n",
       "31 -323.746765  152.143822  18    val    data/toy_ds/18/val.lmdb      652\n",
       "32 -311.808000  151.121444  18   test   data/toy_ds/18/test.lmdb      652\n",
       "33 -321.685422  150.912688  12    val    data/toy_ds/12/val.lmdb      650\n",
       "34 -322.652096  150.099840  12  train  data/toy_ds/12/train.lmdb     1954\n",
       "35 -321.417012  153.527547  12   test   data/toy_ds/12/test.lmdb      651\n",
       "36 -321.874951  150.566060   8  train   data/toy_ds/8/train.lmdb     1953\n",
       "37 -323.746765  152.143822   8   test    data/toy_ds/8/test.lmdb      652\n",
       "38 -321.685422  150.912688   8    val     data/toy_ds/8/val.lmdb      650\n",
       "39 -321.417012  153.527547   2    val     data/toy_ds/2/val.lmdb      651\n",
       "40 -321.685422  150.912688   2   test    data/toy_ds/2/test.lmdb      650\n",
       "41 -322.652096  150.099840   2  train   data/toy_ds/2/train.lmdb     1954\n",
       "42 -318.298420  151.928168   5  train   data/toy_ds/5/train.lmdb     1953\n",
       "43 -332.431521  146.242296   5   test    data/toy_ds/5/test.lmdb      650\n",
       "44 -323.746765  152.143822   5    val     data/toy_ds/5/val.lmdb      652\n",
       "45 -321.417012  153.527547  15   test   data/toy_ds/15/test.lmdb      651\n",
       "46 -325.952307  149.862578  15  train  data/toy_ds/15/train.lmdb     1952\n",
       "47 -311.808000  151.121444  15    val    data/toy_ds/15/val.lmdb      652\n",
       "48 -323.746765  152.143822  11   test   data/toy_ds/11/test.lmdb      652\n",
       "49 -311.808000  151.121444  11    val    data/toy_ds/11/val.lmdb      652\n",
       "50 -325.176057  150.346956  11  train  data/toy_ds/11/train.lmdb     1951\n",
       "51 -321.874951  150.566060   1  train   data/toy_ds/1/train.lmdb     1953\n",
       "52 -323.746765  152.143822   1    val     data/toy_ds/1/val.lmdb      652\n",
       "53 -321.685422  150.912688   1   test    data/toy_ds/1/test.lmdb      650\n",
       "54 -332.431521  146.242296   6   test    data/toy_ds/6/test.lmdb      650\n",
       "55 -321.417012  153.527547   6    val     data/toy_ds/6/val.lmdb      651\n",
       "56 -319.077396  151.483806   6  train   data/toy_ds/6/train.lmdb     1954\n",
       "57 -321.685422  150.912688  16    val    data/toy_ds/16/val.lmdb      650\n",
       "58 -325.860653  150.748462  16  train  data/toy_ds/16/train.lmdb     1953\n",
       "59 -311.808000  151.121444  16   test   data/toy_ds/16/test.lmdb      652"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
